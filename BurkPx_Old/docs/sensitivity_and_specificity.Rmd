---
title: "Sensitivity and Specificity"
author: "Derek Sonderegger"
date: "`r Sys.Date()`"
output: rmarkdown::word_document
#output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Sensitivity and Specificity}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE
)
```

```{r, warning=FALSE, message=FALSE}
# I haven't uploaded BurkPx to GitHub yet, but eventually we'll be
# able to just download the BurkPx package. 
# library(devtools)                          
# install_github('dereksonderegger/BurkPx')  
library(BurkPx)
library(ggplot2)
```


# Human ROC analysis on Human models
*Note to self:  I need to ask Erik for a description of the human trials we used so as to 
document what data we used to fit the models.*

We first split the patients into test/training sets and then fit all the various models (IgG, IgM, IgGM, etc)
using only patients from the training set.  Because we have 100 Meliod patients, then 50 of those patients get
assigned to the test group and 50 to the training group.  Likewise of the 400 controls, 200 get assigned to the
test set and 200 to the training. 

Once the patients have been assigned to either the test or training set, all of the patients serologies are
included in the set.  This means that a single patient with many serologies might have an oversized effect. But
we did this to try to keep our sample sizes as high as possible.

## Model Selection
To assess how well the models work, we will look at the Area Under the Curve (AUC) for the 
Reciever-Operator Curve (ROC). To generate this by week, We take the human data and split it 
into Healthy, Week 1, Week 2, etc. For each of the Weeks, we calculate probability of infection 
for the the Healthy and Infected groups using the six different human models. 

ATPD, imps  : we've run out of these lab supplies...

```{r}
#################################################
##            ROC for each model               ##
#################################################
time = 'Week1'
method = 'LASSO'
type = 'IgG'

AUC_results <- NULL
for(time in c('Week1','Week2','Week3', 'Week4+')){
  for(method in c('LASSO', 'Ridge', 'HCP1')){
    for(type in c('IgM', 'IgG', 'IgGM')){
      if( type %in% c('IgM', 'IgG') ){
        df <- Human_BurkPx_test %>%
          filter(Type == type) %>% filter(TimeGroup %in% c('Healthy', time)) %>%
          spread(Antigen, Value) %>%
          # group_by(PatientID) %>% sample_n(1) %>%  # Use only 1 replicant from each patient
          group_by() %>% select(-PatientID, -SerumID, -TimeGroup, -Type, -Rep) %>% complete()
      }else{
        df <- Human_BurkPx_test %>%
          group_by(PatientID, Type, Rep) %>%
          unite( 'Antigen', Type, Antigen ) %>%
          filter(TimeGroup %in% c('Healthy', time)) %>%
          spread(Antigen, Value) %>%
          # group_by(PatientID) %>% sample_n(1) %>%  # Use only 1 replicant from each patient
          group_by() %>% select(-PatientID, -TimeGroup, -Rep)
      }

      df$p <- predict(models[[str_c('Human_',type,'_',method)]], 
                      newdata=df, na.action = na.pass) %>% 
              as.vector()
      temp <- pROC::roc(Status ~ p, data=df)
      AUC_results <- AUC_results %>%
        rbind( data.frame(Type = type, TimeGroup=time, method=method, AUC=pROC::auc(temp) ) )
      
      df$p <- predict(models[[str_c('Human_Full_',type,'_',method)]],
                      newdata=df, na.action=na.pass) %>%
              as.vector()
      temp <- pROC::roc(Status ~ p, data=df)
      AUC_results <- AUC_results %>%
        rbind( data.frame(Type = str_c('Full_',type), TimeGroup=time, method=method, AUC=pROC::auc(temp) ) )
    }
  }
}
```

```{r,fig.height=2.5, fig.width=6}
ggplot(AUC_results, aes(x=TimeGroup, y=AUC, color=method)) +
  facet_grid(.~Type) + 
  geom_point() + 
  geom_line(aes(x=as.numeric(TimeGroup))) +
  theme(axis.text.x = element_text(angle=-45, vjust=0, hjust=.5) )
```

From this analysis, it is clear that for the first week, we need both the IgG and IgM sereologies. It also seems
that the LASSO is working better than Ridge Regression and that IgG is working better than IgM. However the
best performance is by the IgGM data which uses both IgG and IgM observation values.


## How many covariates are used?
```{r}
# the models object is a list of all the models I created.  The naming convention
# follows the following convention: Human_IgGM_LASSO.  Species_AntigenList_Method

# Which covariates are used in the IgG LASSO model?
temp <- coef( models$Human_Full_IgG_LASSO ) 
data.frame(Antigen=rownames(temp), Coef=as.vector(temp)) %>%
  filter(Antigen != '(Intercept)', Coef != 0 ) 

# Which covariates are used in the IgGM LASSO model?
temp <- coef( models$Human_Full_IgGM_LASSO ) 
data.frame(Antigen=rownames(temp), Coef=as.vector(temp)) %>%
  filter(Antigen != '(Intercept)', Coef != 0 ) 

# Of those, which are used in both IgG and IgM?
data.frame(Antigen=rownames(temp), Coef=as.vector(temp)) %>%
  filter(Antigen != '(Intercept)', Coef != 0 ) %>%
  separate(Antigen, into=c('Type','Antigen'), extra='merge') %>%
  group_by(Antigen) %>% arrange(Antigen) %>% count()

```

## What happens to the IgGM model as we decrease the number of covariates.
```{r}
plot(models$Human_Full_IgGM_LASSO, main='IgGM \n')
```

## What happens to the IgG model as we decrease the number of covariates.
```{r}
plot(models$Human_Full_IgG_LASSO, main='IgG \n')
```

## What happens to the IgM model as we decrease the number of covariates.
```{r}
plot(models$Human_Full_IgM_LASSO, main='IgM \n')
```


I am a little concerned with how large the IgGM model is, but considering our 
sample sizes..
```{r}
Human_BurkPx %>%
  group_by(PatientID, Status) %>%
  count() %>% 
  group_by(Status) %>% count() %>%
  group_by() %>% mutate(perc = nn/sum(nn) )
```
maybe this isn't a big deal.  The data consists of nearly 500 subjects split 
80% / 20% between Healthy and Melioid.

